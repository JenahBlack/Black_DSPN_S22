{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szkkhiCZDF52"
   },
   "source": [
    "# Homework 5:  Linear models, continued\n",
    "This homework assignment is designed to give you a deeper understanding of linear models. First, we'll dive into the math behind the closed-form solution of maximum likelihood estimation. **In the first section below, write your answers using Latex equation formatting.**\n",
    "\n",
    "*Note: Check out [this page](https://gtribello.github.io/mathNET/assets/notebook-writing.html) and [this page](https://towardsdatascience.com/write-markdown-latex-in-the-jupyter-notebook-10985edb91fd) for resources on how to do Latex formatting. You can also double click on the question cells in this notebook to see how math is formatted in the questions.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJscNReoylRt"
   },
   "source": [
    "---\n",
    "## 1. Deriving the Maximum Likelihood Estimate for Simple Linear Regression (6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nH82gwuymPi0"
   },
   "source": [
    "Using the mean squared error (MSE) as your objective function (the thing you're trying to minimize when you fit your model) allows for a closed form solution to finding the maximum likelihood estimate (MLE) of your model parameters in linear regression. Let’s consider the simple, single predictor variable model, i.e. simple linear regression :  $Y= \\beta_0 + \\beta_1 X $. \n",
    "\n",
    "a) Use algebra to show how you can expand out $MSE(\\beta_0, \\beta_1)$ to get from i to ii below.\n",
    "\n",
    "> _i)_ $E[ (Y-(\\beta_0 + \\beta_1 X))^2]$\n",
    "\n",
    "> _ii)_ $E[Y^2] -2 \\beta_0E[Y]-2 \\beta_1 Cov[X,Y]-2 \\beta_1 E[X]E[Y]+ \\beta_0^2 +2 \\beta_0 \\beta_1 E[X]+\\beta_1^2 Var[X]+ \\beta_1^2 (E[X])^2$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dn2hveNho-Of"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "> _i)_ $E[ (Y-(\\beta_0 + \\beta_1 X))^2]$\n",
    "\n",
    "\n",
    "> _ii)_ $E[ (Y-(\\beta_0 + \\beta_1 X)) * (Y-(\\beta_0 + \\beta_1 X))]$\n",
    "\n",
    "Foil highest-level term\n",
    "\n",
    "> _iii)_ $E[ Y^2 -2 \\beta_0*Y -2 \\beta_1*YX] - E[(\\beta_0 + \\beta_1X)^2]$  \n",
    "\n",
    "Foil second term\n",
    "\n",
    "> _iv)_ $E[Y^2] -2 \\beta_0 E[Y] -2 \\beta_1 E[YX] + E[\\beta_0^2] + 2\\beta_0\\beta_1E[X] + \\beta_1^2 E[X^2] $ \n",
    "\n",
    "Expand\n",
    "\n",
    "> _v)_ $E[Y^2] -2 \\beta_0E[Y]-2 \\beta_1 Cov[X,Y]-2 \\beta_1 E[X]E[Y]+ \\beta_0^2 +2 \\beta_0 \\beta_1 E[X]+\\beta_1^2 Var[X]+ \\beta_1^2 E[X]^2$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCr46r9xwRXP"
   },
   "source": [
    "b) Prove that the MLE of $\\beta_0$ is $E[Y]- \\beta_1 E[X]$ by taking the derivative of _ii_ above, with respect to $\\beta_0$, setting the derivative to zero, and solving for $\\beta_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ul-PZyLbwTCQ"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "> _i)_ $\\frac{d}{d\\beta_0} E[Y^2] -2 \\beta_0E[Y]-2 \\beta_1 Cov[X,Y]-2 \\beta_1 E[X]E[Y]+ \\beta_0^2 +2 \\beta_0 \\beta_1 E[X]+\\beta_1^2 Var[X]+ \\beta_1^2 E[X]^2 $\n",
    "\n",
    "Take the derivative\n",
    "\n",
    "> _ii)_ $ 0 -2E[Y] + 0 + 0 + 2\\beta_0 + 2\\beta_1E[x] + 0 + 0$\n",
    "\n",
    "Set equal to zero\n",
    "\n",
    "> _iii)_ $ 0 = -2E[Y] + 2\\beta_0 + 2\\beta_1E[x]$\n",
    "\n",
    "Solve for $\\beta_0$\n",
    "\n",
    "> _iv)_ $ -2\\beta_0 = -2E[Y] + 2\\beta_1E[x]$\n",
    "\n",
    "> _v)_ $ \\beta_0 = E[Y] - \\beta_1E[x]$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uv4Z7afw4gB"
   },
   "source": [
    "c) Prove that the MLE for $\\beta_1$ is $Cov[X,Y]/Var[X]$ by taking the derivative of equation _ii_ above, with respect to $\\beta_1$, setting the derivative to zero, and solving for $\\beta_1$. *Hint: after you've simplified / expanded a bit, plug in the solution for $\\beta_0$ from part b.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWTFZ6ZSw6sh"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "> _i)_ $\\frac{d}{d\\beta_1} E[Y^2] -2 \\beta_0E[Y]-2 \\beta_1 Cov[X,Y]-2 \\beta_1 E[X]E[Y]+ \\beta_0^2 +2 \\beta_0 \\beta_1 E[X]+\\beta_1^2 Var[X]+ \\beta_1^2 E[X]^2 $\n",
    "\n",
    "Take the derivative\n",
    "\n",
    "> _ii)_ $ 0 - 0 - 2Cov[X,Y] - 2 E[X]E[Y] + 0 + 2\\beta_0E[X] + 2Var[X]\\beta_1 + 2E[X]^2\\beta_1$\n",
    "\n",
    "Simplify, and sub in eqaution v from 1b for $\\beta_0$\n",
    "\n",
    "> _iii)_ $ -2Cov[X,Y] - 2E[X]E[Y] + 2E[X](E[Y] - \\beta_1E[x]) + 2Var[X]\\beta_1 + 2E[X]^2\\beta_1$\n",
    "\n",
    "Simplify the inner $\\beta_0$ section\n",
    "\n",
    "> _iv)_ $ -2Cov[X,Y] - 2E[X]E[Y] + 2E[X]E[Y] - 2E[X]^2\\beta_1 + 2Var[X]\\beta_1 + 2E[X]^2\\beta_1$\n",
    "\n",
    "> _v)_ $ -2Cov[X,Y] + 2Var[X]\\beta_1$\n",
    "\n",
    "Set equal to zero and solve for $\\beta_1$\n",
    "\n",
    "> _vi)_ $ 0 = -2Cov[X,Y] + 2Var[X]\\beta_1$ \n",
    "\n",
    "> _vii)_ $ -2Var[X]\\beta_1 = -2Cov[X,Y]$\n",
    "\n",
    "> _viii)_ $ \\beta_1 = \\frac{Cov[X,Y]}{Var[X]}$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66X264ZpDF58"
   },
   "source": [
    "---\n",
    "## 2. Connecting to data (4 points)\n",
    "\n",
    "Now let's connect this to some real data. Once again we'll be using the  **unrestricted_trimmed_1_7_2020_10_50_44.csv** file from the *Homework/hcp_data* folder in the class GitHub repository. \n",
    "\n",
    "​\n",
    "This data is a portion of the [Human Connectome Project database](http://www.humanconnectomeproject.org/). It provides measures of cognitive tasks and brain morphology measurements from 1206 participants. The full description of each variable is provided in the **HCP_S1200_DataDictionary_April_20_2018.csv** file in the *Homework/hcp_data* folder in the class GitHub repository. \n",
    "\n",
    "a) Use the `setwd` and `read.csv` functions to load data from the **unrestricted_trimmed_1_7_2020_10_50_44.csv** file. Then use the `tidyverse` tools make a new dataframe `d1` that only inclues the subject ID (`Subject`), Flanker Task performance (`Flanker_Unadj`), and total grey matter volume (`FS_Total_GM_Vol`) variables and remove all _NA_ values.\n",
    "\n",
    "Use the `head` function to look at the first few rows of each data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5637,
     "status": "ok",
     "timestamp": 1616440721755,
     "user": {
      "displayName": "Patience Stevens",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64",
      "userId": "01994571539255174942"
     },
     "user_tz": 240
    },
    "id": "PZ0lngBjDF58",
    "outputId": "a3c4f688-d665-4d79-8250-56c4d45465e2"
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3owDQ0U2Ewn"
   },
   "source": [
    "b) Now we're going to see if the solutions we proved above actually line up with the model fit that R gives us (it should...). Calculate what the $\\beta_0$ and $\\beta_1$ coefficients should be for a simple linear regression model using `Flanker_Unadj` as $Y$ and `FS_Total_GM_Vol` as $X$. Use the formulas we derived above ($\\beta_1 = Cov[XY]/Var[X]$ , $\\beta_0 = E[Y] - \\beta_1E[X]$). Then use `lm()` to compare the coefficients you calculated with the ones R gives you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1614907277511,
     "user": {
      "displayName": "Patience Stevens",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64",
      "userId": "01994571539255174942"
     },
     "user_tz": 300
    },
    "id": "mWvD8shRDF5_",
    "outputId": "02f91143-c36c-4e9d-dce1-d81f4cbd71b4"
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcnXbsZvDF6B"
   },
   "source": [
    "**DUE:** 5pm EST, March 15, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aG5swCweDF6B"
   },
   "source": [
    "**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here. \n",
    "> Asal Yunusova, Emefa Akwayena, Julia Conti\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Homework5_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
